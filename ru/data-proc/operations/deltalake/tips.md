# Советы по настройке и применению Delta Lake

## Оптимизация записи в S3-совместимые хранилища {#s3-algorithm}

Если часть данных в рамках задания представлена в форматах, отличных от таблиц Delta Lake, то для оптимизации записи данных в S3-совместимые хранилища [настройте коммиттеры S3A](../../tutorials/copy-files-from-object-storage.md#s3a-committers).

Если все данные в рамках задания хранятся в таблицах Delta Lake, то настройка коммиттеров S3A не нужна. Delta Lake использует свой алгоритм управления записью в S3-совместимые хранилища, функционально эквивалентный коммиттерам S3A.

## Увеличение эффективности работы оператора OPTIMIZE {#optimize}

[Оператор OPTIMIZE](https://docs.delta.io/latest/optimizations-oss.html#compaction-bin-packing) в Delta Lake 2.0.2 повышает скорость запросов на чтение из таблицы за счет того, что объединяет несколько мелких файлов в более крупные. Это объединение происходит в рамках нескольких параллельных заданий. Максимальное количество таких параллельных заданий регулируется [свойством](../../concepts/settings-list.md) `spark.databricks.delta.optimize.maxThreads`, и по умолчанию составляет `10`.

Чтобы ускорить выполнение процедуры оптимизации при обработке больших таблиц, [увеличьте](../../concepts/settings-list.md#change-properties) значение для этого свойства. Вы можете использовать намного большие значения, например `100` или `1000`, если ресурсы кластера позволяют запустить такое количество параллельных операций.

## Синтаксис для конвертации партиционированных таблиц {#partitioned-syntax}

Оператор `CONVERT TO DELTA` преобразует обычные таблицы Spark SQL в формат Delta Lake. Чтобы преобразовать партиционированную таблицу, укажите в запросе колонки партиционирования:

```sql
CONVERT TO DELTA table_name PARTITIONED BY (part_col_1 INT, part_col_2 INT);
```

## Принудительная очистка истории изменений таблицы {#forced-vacuum}

По умолчанию Delta Lake хранит историю изменений таблицы в течение 30 суток. Этот период определен на уровне таблицы в параметре `delta.logRetentionDuration` и изменить его можно командой:

```sql
ALTER TABLE <схема_и_имя_таблицы> SET TBLPROPERTIES ('delta.logRetentionDuration' = "interval <интервал>")
```

Подробнее об управлении параметрами таблиц см. в [документации Delta Lake](https://docs.delta.io/latest/delta-batch.html#table-properties).

Чтобы принудительно очистить историю изменений таблицы:

1. Реорганизуйте данные в таблице, чтобы повысить эффективность доступа:

    ```sql
    OPTIMIZE <имя_таблицы>;
    ```

1. Разрешите удаление всей истории изменений:

    ```sql
    SET spark.databricks.delta.retentionDurationCheck.enabled = false;
    ```

1. Очистите историю изменений:

    ```sql
    VACUUM <имя_таблицы> RETAIN 0 HOURS;
    ```
